#!/usr/bin/env bash
set -e

# Mark that we're running inside the rebuild-nixos wrapper
# This allows Claude Code hooks to permit nixos-rebuild calls from within this script
export NIXOS_REBUILD_WRAPPER=1

# Parse command line arguments
VERBOSE=false
if [[ "$1" == "--verbose" ]] || [[ "$1" == "-v" ]]; then
    VERBOSE=true
fi

# Setup logging
LOG_DIR="$HOME/.claude/.logs"
mkdir -p "$LOG_DIR"
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
LOG_FILE="$LOG_DIR/rebuild-$TIMESTAMP.log"

# Colors for output
BLUE='\033[0;34m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Tracking arrays for summary
declare -a WARNINGS=()
declare -a ACTIONS=()
declare -a STATS=()

# Helper functions
log_step() {
    local step_time=$(date +%H:%M:%S)
    echo -e "${BLUE}[$step_time]${NC} $1"
}

log_success() {
    echo -e "${GREEN}✅${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}⚠️${NC}  $1"
    WARNINGS+=("$1")
}

log_error() {
    echo -e "${RED}❌${NC} $1"
}

add_action() {
    ACTIONS+=("$1")
}

add_stat() {
    STATS+=("$1")
}

# Progress indicator with time estimates and status
show_progress() {
    local step_name="$1"
    local pid="$2"
    local history_file="$LOG_DIR/build-times.log"
    local start_time=$(date +%s)

    # Calculate average from last 5 builds if available
    local avg_time=""
    if [ -f "$history_file" ]; then
        avg_time=$(tail -5 "$history_file" | awk '{sum+=$1; count++} END {if(count>0) print int(sum/count)}')
    fi

    local spinstr='⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏'
    local last_status=""

    while kill -0 "$pid" 2>/dev/null; do
        local elapsed=$(($(date +%s) - start_time))
        local mins=$((elapsed / 60))
        local secs=$((elapsed % 60))

        # Build progress message
        local msg=$(printf "⏱️  %02d:%02d" $mins $secs)

        # Add ETA if we have historical data
        if [ -n "$avg_time" ] && [ "$avg_time" -gt 0 ]; then
            local remaining=$((avg_time - elapsed))
            if [ $remaining -gt 0 ]; then
                local eta_mins=$((remaining / 60))
                local eta_secs=$((remaining % 60))
                msg="$msg | ~%02d:%02d remaining"
                msg=$(printf "$msg" $eta_mins $eta_secs)
            fi
        fi

        # Try to get current status from log file
        if [ -f "$LOG_FILE" ]; then
            local current_status=$(tail -5 "$LOG_FILE" 2>/dev/null | grep -E "building|copying|installing|activating|running|switching|updating" | tail -1)

            if [ -n "$current_status" ]; then
                # Extract package name from nix store path if present
                if echo "$current_status" | grep -q "/nix/store/"; then
                    # Extract just the package name (hash-packagename.drv -> packagename)
                    local pkg_name=$(echo "$current_status" | grep -oP '/nix/store/[a-z0-9]+-\K[^/]+' | head -1 | sed 's/\.drv$//')
                    if [ -n "$pkg_name" ]; then
                        # Get the action (building, copying, etc.)
                        local action=$(echo "$current_status" | grep -oP '^[a-z]+' | head -1)
                        last_status="$action $pkg_name"
                    else
                        last_status=$(echo "$current_status" | cut -c1-60)
                    fi
                else
                    last_status=$(echo "$current_status" | cut -c1-60)
                fi
            fi
        fi

        # Show status if available
        local status_display=""
        if [ -n "$last_status" ]; then
            status_display=" | ${last_status}"
        fi

        # Show spinner and message (allow long lines)
        local spinchar="${spinstr:0:1}"
        spinstr="${spinstr:1}${spinchar}"
        printf "\r$spinchar  $msg$status_display"
        printf "$(tput el)"  # Clear to end of line
        sleep 0.2
    done

    # Clear progress line
    printf "\r$(tput el)"

    # Record build time for future estimates
    local total_time=$(($(date +%s) - start_time))
    echo "$total_time" >> "$history_file"

    # Keep only last 10 builds
    if [ -f "$history_file" ]; then
        tail -10 "$history_file" > "$history_file.tmp"
        mv "$history_file.tmp" "$history_file"
    fi
}

# Start rebuild
echo ""
echo "╔════════════════════════════════════════════════════════════╗"
echo "║            NixOS System Rebuild & Configuration            ║"
echo "╚════════════════════════════════════════════════════════════╝"
echo ""

if [ "$VERBOSE" = true ]; then
    echo "🔍 Verbose mode enabled"
    echo "📁 Logs: $LOG_FILE"
fi

# Cache sudo credentials early (activation step needs sudo)
echo "🔐 This rebuild requires sudo privileges for system activation."
sudo -v || { log_error "Failed to obtain sudo access"; exit 1; }

# === PHASE 1: Update Flake Inputs ===
# Updates nix flake lock file to get latest package versions
# SMART UPDATE: Uses --refresh for locally-maintained repos to bypass cache
# Side effects: Modifies flake.lock, may pull in breaking changes
# Exit on failure: Yes (can't build without valid inputs)

log_step "Updating flake inputs..."

# Define locally-maintained inputs that need cache bypass
LOCAL_INPUTS=(
    "code-cursor-nix"
    "whisper-dictation"
    "claude-automation"
    "claude-code-nix"  # Also locally maintained by you
)

if [ "$VERBOSE" = true ]; then
    echo "📦 Updating external inputs (using cache)..."
    nix flake update nixpkgs home-manager 2>&1 | tee -a "$LOG_FILE"

    echo "🚀 Updating local inputs (bypassing cache with --refresh)..."
    for input in "${LOCAL_INPUTS[@]}"; do
        echo "   - Updating $input..."
        nix flake update "$input" --refresh 2>&1 | tee -a "$LOG_FILE"
    done
else
    # Quiet mode: Update external inputs first (cached)
    nix flake update nixpkgs home-manager &>>"$LOG_FILE"

    # Update local inputs with --refresh to bypass cache
    for input in "${LOCAL_INPUTS[@]}"; do
        nix flake update "$input" --refresh &>>"$LOG_FILE"
    done
fi

log_success "Flake inputs updated (local repos refreshed)"
add_action "Updated flake.lock with cache bypass for local repos"

# === PHASE 2: Test Build ===
# Builds new configuration WITHOUT activating it (safe to fail)
# This catches build errors before touching running system
# Exit on failure: Yes (don't activate broken config)
# Perform a test build
log_step "Performing test build..."

if [ "$VERBOSE" = true ]; then
    # Verbose mode - show all output
    NEW_CONFIG_PATH=$(NIXPKGS_ALLOW_UNFREE=1 nix build --no-link --print-out-paths --impure .#nixosConfigurations."nixos".config.system.build.toplevel 2>&1 | tee -a "$LOG_FILE" | tail -1)
else
    # Non-verbose mode - show progress indicator
    NIXPKGS_ALLOW_UNFREE=1 nix build --no-link --print-out-paths --impure .#nixosConfigurations."nixos".config.system.build.toplevel > /tmp/nixbuild-output-$$.tmp 2>>"$LOG_FILE" &
    BUILD_PID=$!
    show_progress "test-build" $BUILD_PID
    wait $BUILD_PID
    BUILD_EXIT=$?

    if [ $BUILD_EXIT -ne 0 ]; then
        log_error "Test build failed (exit code: $BUILD_EXIT)"
        echo "Check logs: $LOG_FILE"
        rm -f /tmp/nixbuild-output-$$.tmp
        exit 1
    fi

    NEW_CONFIG_PATH=$(cat /tmp/nixbuild-output-$$.tmp)
    rm -f /tmp/nixbuild-output-$$.tmp
fi

log_success "Test build successful"

# === PHASE 3: Activate Configuration ===
# Switches running system to new configuration (requires sudo)
# This is the critical step - system state changes here
# Exit on failure: Yes (activation failed, system unchanged)
# Rollback available: Use 'sudo nixos-rebuild switch --rollback'
# Activate the new configuration
log_step "Activating new configuration..."

if [ "$VERBOSE" = true ]; then
    # Verbose mode - show all output
    if sudo NIXPKGS_ALLOW_UNFREE=1 nixos-rebuild switch --flake . --impure 2>&1 | tee -a "$LOG_FILE"; then
        ACTIVATE_EXIT=0
    else
        ACTIVATE_EXIT=$?
    fi
else
    # Non-verbose mode - show progress indicator
    sudo NIXPKGS_ALLOW_UNFREE=1 nixos-rebuild switch --flake . --impure 2>>"$LOG_FILE" &
    ACTIVATE_PID=$!
    show_progress "activation" $ACTIVATE_PID
    wait $ACTIVATE_PID
    ACTIVATE_EXIT=$?
fi

# Check activation result
if [ $ACTIVATE_EXIT -ne 0 ]; then
    echo ""  # Ensure we're on a new line
    log_error "Activation failed (exit code: $ACTIVATE_EXIT)"
    echo "📁 Check logs: $LOG_FILE"
    exit 1
fi

echo ""  # Ensure we're on a new line after progress indicator
log_success "Configuration activated"
add_action "Switched to new NixOS configuration"

# === PHASE 4: Update Claude Code Configurations ===
# Regenerates 5 Claude context files (CLAUDE.md, permissions, MCP, etc.)
# Uses claude-nixos-automation flake (local if available, GitHub fallback)
# Exit on failure: No (continue with warnings - not critical to system)
# Update Claude Code configurations
log_step "Updating Claude Code configurations..."
echo ""

# Use local flake for automation (development mode)
AUTOMATION_FLAKE="$HOME/claude-nixos-automation"

if [ "$VERBOSE" = true ]; then
    # Verbose mode: show all output
    if [ -d "$AUTOMATION_FLAKE" ]; then
        if (cd ~/nixos-config && nix run "$AUTOMATION_FLAKE#update-all" 2>&1 | tee -a "$LOG_FILE"); then
            AUTOMATION_EXIT=0
        else
            AUTOMATION_EXIT=$?
        fi
    else
        # Fallback to GitHub
        if (cd ~/nixos-config && nix run github:jacopone/claude-nixos-automation#update-all 2>&1 | tee -a "$LOG_FILE"); then
            AUTOMATION_EXIT=0
        else
            AUTOMATION_EXIT=$?
        fi
    fi
else
    # Quiet mode: redirect to log, show only summary
    if [ -d "$AUTOMATION_FLAKE" ]; then
        if (cd ~/nixos-config && nix run "$AUTOMATION_FLAKE#update-all" &>"$LOG_FILE.automation"); then
            AUTOMATION_EXIT=0
        else
            AUTOMATION_EXIT=$?
        fi
    else
        # Fallback to GitHub
        if (cd ~/nixos-config && nix run github:jacopone/claude-nixos-automation#update-all &>"$LOG_FILE.automation"); then
            AUTOMATION_EXIT=0
        else
            AUTOMATION_EXIT=$?
        fi
    fi

    # Extract stats from generated files (automation logs suppress output)
    if [ -f "./CLAUDE.md" ]; then
        TOOLS_COUNT=$(grep "\*\*Total System Tools\*\*:" ./CLAUDE.md 2>/dev/null | grep -oP '\d+' || echo "?")
        ABBREV_COUNT=$(grep "\*\*Fish Abbreviations\*\*:" ./CLAUDE.md 2>/dev/null | grep -oP '\d+' || echo "?")

        add_stat "System tools: $TOOLS_COUNT"
        add_stat "Fish abbreviations: $ABBREV_COUNT"
    fi

    # Check automation log for warnings
    if [ -f "$LOG_FILE.automation" ]; then
        WARNING_COUNT=$(grep -c "WARNING:" "$LOG_FILE.automation" 2>/dev/null || true)
        WARNING_COUNT=${WARNING_COUNT:-0}

        if [ "$WARNING_COUNT" -gt 0 ]; then
            log_warning "$WARNING_COUNT warnings during automation (see $LOG_FILE.automation)"
        fi
    fi
fi

if [ $AUTOMATION_EXIT -eq 0 ]; then
    echo ""
    log_success "Claude Code configurations updated"
    add_action "Updated 5 Claude configuration files"

    # Show detailed file update summary
    echo ""
    echo "📄 Files updated by automation:"
    echo ""

    # Function to show file status
    show_file_status() {
        local file="$1"
        local description="$2"
        local scope="$3"

        if [ -f "$file" ]; then
            local size=$(du -h "$file" 2>/dev/null | cut -f1)
            local size_bytes=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo "0")
            local status="✓"
            local change_indicator=""

            # Sanity check: 0 bytes = broken
            if [ -z "$size_bytes" ] || [ "$size_bytes" -eq 0 ]; then
                echo -e "  ${RED}✗ $description (BROKEN - 0 bytes!)${NC}"
                echo "     ↳ $scope"
                return
            fi

            # Check if file is in git and what changed
            if git ls-files --error-unmatch "$file" &>/dev/null 2>&1; then
                if git diff --quiet "$file" 2>/dev/null; then
                    change_indicator=" ${GREEN}unchanged${NC}"
                else
                    # Count lines changed
                    local changes=$(git diff --numstat "$file" 2>/dev/null | awk '{print "+"$1" -"$2}')
                    if [ -n "$changes" ]; then
                        change_indicator=" ${YELLOW}updated${NC} ($changes lines)"
                    else
                        change_indicator=" ${YELLOW}updated${NC}"
                    fi
                fi
            else
                change_indicator=" ${BLUE}untracked${NC}"
            fi

            echo -e "  $status $description [$size]$change_indicator"
            echo "     ↳ $scope"
        else
            echo -e "  ${RED}✗ $description (FILE NOT FOUND - automation failed!)${NC}"
            echo "     ↳ $scope"
        fi
    }

    # System-wide files (global, all projects)
    show_file_status "$HOME/.claude/CLAUDE.md" \
        "System tools inventory" \
        "Global: AI-aware tool documentation (116 tools)"

    show_file_status "$HOME/.claude/CLAUDE-USER-POLICIES.md" \
        "Your personal policies" \
        "Global: Git commit rules, rebuild restrictions, doc standards"

    echo ""

    # Project-specific files (this project only)
    show_file_status "./CLAUDE.md" \
        "Project context" \
        "Local: Tech stack, commands, architecture (trackable in git)"

    show_file_status "./.claude/settings.local.json" \
        "Security permissions" \
        "Local: Auto-generated allow/deny rules for this project"

    show_file_status "./.claude/CLAUDE.local.md" \
        "Machine state" \
        "Local: Hardware info, services, git branches (gitignored)"

    echo ""

    # === PHASE 5: MCP Usage Analytics ===
    # Analyzes MCP server utilization across all sessions
    # Marks sessions as ANALYZED (Phase 2 lifecycle)
    # Generates .claude/mcp-analytics.md report
    # Exit on failure: No (non-critical analytics)
    # Run MCP usage analytics (marks sessions as ANALYZED - Phase 2)
    log_step "Analyzing MCP servers and marking sessions..."
    if [ -d "$AUTOMATION_FLAKE" ]; then
        MCP_CMD="nix run $AUTOMATION_FLAKE#update-mcp-usage-analytics"
    else
        MCP_CMD="nix run github:jacopone/claude-nixos-automation#update-mcp-usage-analytics"
    fi

    if (cd ~/nixos-config && $MCP_CMD 2>/dev/null); then
        log_success "MCP analysis completed"
        echo "  ↳ Sessions automatically marked as ANALYZED (Phase 2 lifecycle)"
    else
        log_warning "MCP analysis had issues (non-critical)"
    fi

    # Extract MCP stats (even if command failed, use existing file)
    if [ -f ~/nixos-config/.claude/mcp-analytics.md ]; then
        # Extract stats from mcp-analytics.md (match actual template format)
        TOTAL_CONFIGURED=$(grep "^### Configured Servers" ~/nixos-config/.claude/mcp-analytics.md 2>/dev/null | grep -oP '\(\K\d+' || echo "?")
        MCP_CONNECTED=$(grep "^- ✅ \*\*Connected\*\*:" ~/nixos-config/.claude/mcp-analytics.md 2>/dev/null | grep -oP '\d+' | head -1 || echo "?")
        TOTAL_SESSIONS=$(grep "^\*\*Total sessions analyzed\*\*:" ~/nixos-config/.claude/mcp-analytics.md 2>/dev/null | grep -oP '\d+' || echo "?")

        # Add to statistics if we have valid data
        if [ "$MCP_CONNECTED" != "?" ] && [ "$TOTAL_CONFIGURED" != "?" ]; then
            add_stat "MCP: $MCP_CONNECTED/$TOTAL_CONFIGURED connected | $TOTAL_SESSIONS sessions"
            echo "  ↳ MCP stats from: .claude/mcp-analytics.md"
        fi
    fi

    # === PHASE 6: Tool Usage Analytics ===
    # Tracks which system tools are actually used vs merely installed
    # Enables data-driven decisions on tool adoption
    # Exit on failure: No (non-critical analytics)
    # Run tool usage analytics (Phase 1)
    log_step "Analyzing system tool usage..."
    if [ -d "$AUTOMATION_FLAKE" ]; then
        TOOL_CMD="python3 $AUTOMATION_FLAKE/update-tool-usage-analytics.py"
    else
        TOOL_CMD="python3 ~/claude-nixos-automation/update-tool-usage-analytics.py"
    fi

    if (cd ~/nixos-config && $TOOL_CMD 2>/dev/null); then
        # Show brief tool usage status
        if [ -f "./CLAUDE.md" ]; then
            # Extract stats from CLAUDE.md - look for the Tool Usage section
            TOOL_TOTAL=$(grep -A 3 "^## 📦 System Tool Usage" ./CLAUDE.md | grep "Installed" | grep -oP '\*\*Installed\*\*: \K\d+' || echo "?")
            TOOL_USED=$(grep -A 3 "^## 📦 System Tool Usage" ./CLAUDE.md | grep "Used" | grep -oP '\*\*Used\*\*: \K\d+' || echo "?")
            TOOL_ADOPTION=$(grep -A 3 "^## 📦 System Tool Usage" ./CLAUDE.md | grep "Used" | grep -oP '\(\K\d+' || echo "?")

            # Display with clearer format
            if [ "$TOOL_USED" != "?" ] && [ "$TOOL_TOTAL" != "?" ]; then
                log_success "Tool usage: $TOOL_USED/$TOOL_TOTAL tools used (${TOOL_ADOPTION}% adoption)"
            else
                log_success "Tool usage analysis completed"
            fi
            echo "  ↳ Detailed report: .claude/tool-analytics.md"
            add_stat "Tools: $TOOL_USED/$TOOL_TOTAL used | ${TOOL_ADOPTION}% adoption"
        fi
    else
        log_warning "Tool usage analysis had issues (non-critical)"
    fi
else
    log_warning "Claude automation had issues (check logs)"
fi

# === PHASE 7: Adaptive Learning Cycle ===
# Runs 7 parallel ML analyzers to detect optimization opportunities:
# - Permission patterns (auto-approve repeated commands)
# - MCP server utilization (move to project-level if low usage)
# - Context optimization (remove unused CLAUDE.md sections)
# - Workflow patterns (bundle repeated command sequences)
# - Instruction effectiveness (improve low-compliance policies)
# - Cross-project transfers (apply patterns from similar projects)
# - Meta-learning (calibrate detection thresholds)
# Exit on failure: No (learning is optional, system already activated)
# User interaction: Yes (interactive approval of suggestions)
# === ADAPTIVE LEARNING CYCLE ===
echo ""
log_step "Running adaptive learning cycle..."
AUTOMATION_DIR="$HOME/claude-nixos-automation"
if [[ -d "$AUTOMATION_DIR" ]]; then
    # Run WITHOUT pipes to preserve stdin/stdout for user interaction
    # No timeout for interactive mode (user needs time to review and respond)
    # Suppress devenv startup noise but preserve Python output for user
    if (cd "$AUTOMATION_DIR" && devenv shell -- python run-adaptive-learning.py --interactive 2> >(grep -v "Building shell" >&2)); then
        LEARNING_EXIT=0
        log_success "Adaptive learning cycle complete"
        add_action "Adaptive learning: suggestions reviewed interactively"
    else
        LEARNING_EXIT=$?
        if [ $LEARNING_EXIT -eq 130 ]; then
            log_warning "Adaptive learning interrupted by user (Ctrl+C)"
        else
            log_warning "Adaptive learning had issues (exit code: $LEARNING_EXIT)"
        fi
    fi
else
    log_warning "Adaptive learning not available (automation directory not found)"
fi

# === PHASE 8: User Acceptance ===
# User tests the activated configuration
# Offers rollback if issues found
# Creates git commit if changes accepted
echo ""
log_step "Configuration activated. Please test the changes now."
read -p "Are you satisfied with the changes? (y/n) " -n 1 -r
echo

if [[ $REPLY =~ ^[Yy]$ ]]
then
    log_step "Changes accepted. Staging for commit..."
    git add .

    git status

    # Ask for a commit message
    read -p "Enter a commit message for these changes (or leave blank to skip commit): " commit_message

    if [ -n "$commit_message" ]; then
      log_step "Committing changes..."
      # Use PRE_COMMIT_ALLOW_NO_CONFIG=1 to bypass pre-commit config warning
      # Wrap in error handling so script continues even if commit fails
      if PRE_COMMIT_ALLOW_NO_CONFIG=1 git commit -m "$commit_message" 2>&1; then
        log_success "Created git commit"
        add_action "Created git commit"
      else
        log_warning "Git commit failed (likely pre-commit hook issue)"
        log_warning "Changes are staged but not committed"
        log_warning "You can commit manually later with: git commit -m \"your message\""
        add_action "Staged changes (commit failed - manual commit needed)"
      fi
    else
      log_warning "No commit message provided. Skipping commit."
    fi
else
    log_step "Changes rejected. Rolling back to previous configuration..."
    sudo nixos-rebuild switch --rollback
    log_success "Rollback complete"
    exit 0
fi

# === PHASE 9: Generation Cleanup ===
# Deletes old NixOS generations to free disk space
# User selects which generations to delete
# Runs garbage collection after deletion
# Exit on failure: No (cleanup is optional)
# Clean up old generations
echo ""
log_step "Listing system generations..."
sudo nixos-rebuild list-generations

read -p "Enter the generations you want to delete (separated by space): " generations_to_delete
if [ -n "$generations_to_delete" ]; then
    log_step "Deleting generations: $generations_to_delete"
    sudo nix-env -p /nix/var/nix/profiles/system --delete-generations $generations_to_delete
    log_success "Selected generations deleted"

    log_step "Running garbage collection..."
    nix-collect-garbage
    log_success "Garbage collection complete"
    add_action "Cleaned up old generations"
else
    log_warning "No generations selected for deletion"
fi

# === PHASE 10: Disk Space Analysis ===
# Scans for problematic disk usage patterns:
# - Oversized logs (>100MB = investigate)
# - Large Claude sessions (>5MB = stuck session?)
# - Bloated configs (>1MB = corruption?)
# - Old backups (cleanup candidates)
# Checks learning data health (GREEN/YELLOW/RED risk levels)
# Exit on failure: No (analysis only, no changes made)
# Disk space analysis for problematic areas
echo ""
log_step "Analyzing disk space for issues..."
declare -a DISK_WARNINGS=()

# Check for oversized log files (>100MB = problematic)
LARGE_LOGS=$(fd -t f -s +100M '\.log$' ~ --max-depth 4 2>/dev/null | wc -l)
if [ "$LARGE_LOGS" -gt 0 ]; then
    LARGEST_LOG=$(fd -t f -s +100M '\.log$' ~ --max-depth 4 2>/dev/null | xargs du -h 2>/dev/null | sort -rh | head -1)
    DISK_WARNINGS+=("$LARGE_LOGS log file(s) >100MB: ${LARGEST_LOG}")
fi

# Check learning data disk health (Phase 1.5)
echo ""
log_step "Checking learning data disk health..."

HEALTH_EXIT_CODE=0
# Run health check directly (avoid nix wrapper issues with new files)
if [ -f ~/claude-nixos-automation/check-data-health.py ]; then
    HEALTH_OUTPUT=$(python3 ~/claude-nixos-automation/check-data-health.py 2>&1) || HEALTH_EXIT_CODE=$?
else
    HEALTH_OUTPUT="Health check script not found"
    HEALTH_EXIT_CODE=1
fi

# Parse health stats from output
HEALTH_TOTAL_MB=$(echo "$HEALTH_OUTPUT" | grep "Total:" | grep -oP '\d+(?=MB)' | head -1 || echo "?")
HEALTH_SESSIONS=$(echo "$HEALTH_OUTPUT" | grep "sessions" | grep -oP '\d+(?= sessions)' | head -1 || echo "?")
HEALTH_PERCENTAGE=$(echo "$HEALTH_OUTPUT" | grep "Usage:" | grep -oP '[\d.]+(?=% of disk)' || echo "?")

echo "  • Total learning data: ${HEALTH_TOTAL_MB}MB"
echo "  • Claude sessions: ${HEALTH_SESSIONS}"
echo "  • Disk usage: ${HEALTH_PERCENTAGE}% of total disk"

if [ $HEALTH_EXIT_CODE -eq 2 ]; then
    echo -e "${RED}  🔴 URGENT: Learning data disk usage critical!${NC}"
    DISK_WARNINGS+=("Learning data usage critical - run adaptive learning to extract insights, then cleanup")
elif [ $HEALTH_EXIT_CODE -eq 1 ]; then
    echo -e "${YELLOW}  🟡 Learning data growing - consider cleanup after insights extracted${NC}"
else
    echo -e "${GREEN}  ✅ Learning data disk health is good${NC}"
fi

# Still check for very large individual session files (may indicate stuck sessions)
LARGE_CLAUDE=$(fd -t f -s +5M '\.jsonl$' ~/.claude/projects 2>/dev/null | wc -l)
if [ "$LARGE_CLAUDE" -gt 0 ]; then
    DISK_WARNINGS+=("$LARGE_CLAUDE Claude session(s) >5MB (may indicate stuck sessions)")
fi

# Check for oversized config files (>1MB = investigate)
LARGE_CONFIGS=$(fd -t f -s +1M '\.json$' ~/.config ~/.claude --max-depth 3 2>/dev/null | grep -v "IndexedDB\|chrome" | wc -l)
if [ "$LARGE_CONFIGS" -gt 0 ]; then
    DISK_WARNINGS+=("$LARGE_CONFIGS config file(s) >1MB (should be <100KB)")
fi

# Check for old backup files (>1MB)
LARGE_BACKUPS=$(fd -t f -s +1M -e bak -e backup -e old ~ --max-depth 3 2>/dev/null | wc -l)
if [ "$LARGE_BACKUPS" -gt 0 ]; then
    DISK_WARNINGS+=("$LARGE_BACKUPS backup file(s) >1MB (should archive/delete)")
fi

if [ ${#DISK_WARNINGS[@]} -gt 0 ]; then
    echo ""
    echo -e "${YELLOW}⚠️  Disk space issues detected (size vs expected):${NC}"
    for warning in "${DISK_WARNINGS[@]}"; do
        echo "   • $warning"
        log_warning "Disk: $warning"
    done
    echo ""
    echo "💡 Run these commands to investigate:"
    [ "$LARGE_LOGS" -gt 0 ] && echo "   fd -t f -s +100M '\.log$' ~ --max-depth 4 -x du -h | sort -rh"
    [ "$LARGE_CLAUDE" -gt 0 ] && echo "   fd -t f -s +5M '\.jsonl$' ~/.claude/projects -x du -h | sort -rh"
    [ "$LARGE_CONFIGS" -gt 0 ] && echo "   fd -t f -s +1M '\.json$' ~/.config ~/.claude --max-depth 3 | rg -v 'IndexedDB|chrome'"
    echo ""
fi

# === PHASE 11: Cache Cleanup ===
# Offers to clean large cache directories:
# - UV Python cache, Chrome cache, Yarn/npm/pnpm caches
# User confirms before deletion
# Safe to delete (caches regenerate on demand)
# Exit on failure: No (cleanup is optional)
# Clean up cache directories
echo ""
log_step "Cache cleanup options..."
echo "Large cache directories detected:"
TOTAL_CACHE_SIZE=0
if [ -d ~/.cache/uv ]; then
    SIZE=$(du -sb ~/.cache/uv 2>/dev/null | cut -f1 || echo "0")
    SIZE=${SIZE:-0}
    TOTAL_CACHE_SIZE=$((TOTAL_CACHE_SIZE + SIZE))
    echo "  - UV Python cache: $(du -sh ~/.cache/uv 2>/dev/null | cut -f1)"
fi
if [ -d ~/.cache/google-chrome ]; then
    SIZE=$(du -sb ~/.cache/google-chrome 2>/dev/null | cut -f1 || echo "0")
    SIZE=${SIZE:-0}
    TOTAL_CACHE_SIZE=$((TOTAL_CACHE_SIZE + SIZE))
    echo "  - Google Chrome cache: $(du -sh ~/.cache/google-chrome 2>/dev/null | cut -f1)"
fi
if [ -d ~/.cache/yarn ]; then
    SIZE=$(du -sb ~/.cache/yarn 2>/dev/null | cut -f1 || echo "0")
    SIZE=${SIZE:-0}
    TOTAL_CACHE_SIZE=$((TOTAL_CACHE_SIZE + SIZE))
    echo "  - Yarn cache: $(du -sh ~/.cache/yarn 2>/dev/null | cut -f1)"
fi
if [ -d ~/.cache/ms-playwright ]; then
    SIZE=$(du -sb ~/.cache/ms-playwright 2>/dev/null | cut -f1 || echo "0")
    SIZE=${SIZE:-0}
    TOTAL_CACHE_SIZE=$((TOTAL_CACHE_SIZE + SIZE))
    echo "  - MS Playwright cache: $(du -sh ~/.cache/ms-playwright 2>/dev/null | cut -f1)"
fi
if [ -d ~/.cache/pnpm ]; then
    SIZE=$(du -sb ~/.cache/pnpm 2>/dev/null | cut -f1 || echo "0")
    SIZE=${SIZE:-0}
    TOTAL_CACHE_SIZE=$((TOTAL_CACHE_SIZE + SIZE))
    echo "  - PNPM cache: $(du -sh ~/.cache/pnpm 2>/dev/null | cut -f1)"
fi
if [ -d ~/.npm ]; then
    SIZE=$(du -sb ~/.npm 2>/dev/null | cut -f1 || echo "0")
    SIZE=${SIZE:-0}
    TOTAL_CACHE_SIZE=$((TOTAL_CACHE_SIZE + SIZE))
    echo "  - npm cache: $(du -sh ~/.npm 2>/dev/null | cut -f1)"
fi

TOTAL_CACHE_MB=$((TOTAL_CACHE_SIZE / 1024 / 1024))
if [ $TOTAL_CACHE_MB -gt 0 ]; then
    echo "  Total: ${TOTAL_CACHE_MB}MB"
fi

read -p "Clean these cache directories? (y/n) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    log_step "Cleaning cache directories..."
    [ -d ~/.cache/uv ] && rm -rf ~/.cache/uv && echo "  ✓ UV cache"
    [ -d ~/.cache/google-chrome ] && rm -rf ~/.cache/google-chrome && echo "  ✓ Chrome cache"
    [ -d ~/.cache/yarn ] && rm -rf ~/.cache/yarn && echo "  ✓ Yarn cache"
    [ -d ~/.cache/ms-playwright ] && rm -rf ~/.cache/ms-playwright && echo "  ✓ Playwright cache"
    [ -d ~/.cache/pnpm ] && rm -rf ~/.cache/pnpm && echo "  ✓ PNPM cache"
    [ -d ~/.npm ] && npm cache clean --force 2>/dev/null && echo "  ✓ npm cache"
    [ -d ~/.cache/chromium ] && rm -rf ~/.cache/chromium && echo "  ✓ Chromium cache"
    log_success "Cache cleanup complete (freed ~${TOTAL_CACHE_MB}MB)"
    add_action "Cleared ${TOTAL_CACHE_MB}MB of cache"
else
    log_warning "Cache cleanup skipped"
fi

# === PHASE 12: Claude Session Lifecycle Cleanup ===
# Deletes sessions marked as IMPLEMENTED (insights already extracted)
# Session lifecycle: RAW → ANALYZED → INSIGHTS_GENERATED → IMPLEMENTED
# Only IMPLEMENTED sessions are safe to delete (value captured)
# Exit on failure: No (cleanup is optional)
# Clean up Claude session files (Phase 2: Lifecycle-based cleanup)
if [ -d ~/.claude/projects ]; then
    echo ""
    log_step "Checking Claude session lifecycle..."

    # Consolidated Python script for lifecycle operations (stats + cleanup)
    # Saves ~300ms by avoiding second Python interpreter startup
    LIFECYCLE_OUTPUT=$(python3 <<'PYTHON_EOF'
import sys
from pathlib import Path

# Add claude-nixos-automation to path
sys.path.insert(0, str(Path.home() / "claude-nixos-automation"))

try:
    from claude_automation.analyzers.session_lifecycle_tracker import SessionLifecycleTracker

    tracker = SessionLifecycleTracker()
    stats = tracker.get_lifecycle_stats()

    # Print stats in parseable format
    print(f"STATS:TOTAL:{stats.total_sessions}")
    print(f"STATS:RAW:{stats.raw_count}")
    print(f"STATS:ANALYZED:{stats.analyzed_count}")
    print(f"STATS:INSIGHTS_GENERATED:{stats.insights_generated_count}")
    print(f"STATS:IMPLEMENTED:{stats.implemented_count}")
    print(f"STATS:SAFE_TO_CLEANUP:{stats.safe_to_cleanup_count}")
    print(f"STATS:VALUABLE:{stats.valuable_data_count}")

    # Pre-load safe sessions list and write to temp file for potential cleanup
    # This avoids a second Python interpreter startup (saves ~300ms)
    safe_sessions = tracker.get_safe_to_cleanup_sessions()
    safe_count = len(safe_sessions)
    print(f"CLEANUP:READY:{safe_count}")

    if safe_count > 0:
        import tempfile
        import json
        temp_file = Path(tempfile.gettempdir()) / "claude_safe_sessions.json"
        with open(temp_file, 'w') as f:
            json.dump([str(p) for p in safe_sessions], f)
        print(f"CLEANUP:TEMPFILE:{temp_file}")

except Exception as e:
    # Fallback if lifecycle tracking not available
    print(f"ERROR:{e}")
    print("STATS:TOTAL:?")
    print("STATS:SAFE_TO_CLEANUP:0")
    print("STATS:VALUABLE:?")
    print("CLEANUP:READY:0")
PYTHON_EOF
)

    # Parse lifecycle stats (now with STATS: prefix)
    TOTAL_SESSIONS=$(echo "$LIFECYCLE_OUTPUT" | grep "^STATS:TOTAL:" | cut -d: -f3)
    RAW_COUNT=$(echo "$LIFECYCLE_OUTPUT" | grep "^STATS:RAW:" | cut -d: -f3)
    ANALYZED_COUNT=$(echo "$LIFECYCLE_OUTPUT" | grep "^STATS:ANALYZED:" | cut -d: -f3)
    INSIGHTS_COUNT=$(echo "$LIFECYCLE_OUTPUT" | grep "^STATS:INSIGHTS_GENERATED:" | cut -d: -f3)
    IMPLEMENTED_COUNT=$(echo "$LIFECYCLE_OUTPUT" | grep "^STATS:IMPLEMENTED:" | cut -d: -f3)
    SAFE_COUNT=$(echo "$LIFECYCLE_OUTPUT" | grep "^STATS:SAFE_TO_CLEANUP:" | cut -d: -f3)
    VALUABLE_COUNT=$(echo "$LIFECYCLE_OUTPUT" | grep "^STATS:VALUABLE:" | cut -d: -f3)

    # Display lifecycle statistics
    echo "  📋 Session Lifecycle:"
    echo "     • Total sessions: ${TOTAL_SESSIONS}"
    echo "     • RAW (not analyzed): ${RAW_COUNT}"
    echo "     • ANALYZED: ${ANALYZED_COUNT}"
    echo "     • INSIGHTS_GENERATED: ${INSIGHTS_COUNT}"
    echo "     • IMPLEMENTED (safe to cleanup): ${IMPLEMENTED_COUNT}"
    echo "     • Still valuable: ${VALUABLE_COUNT}"
    echo ""

    # Only offer cleanup if there are IMPLEMENTED sessions
    if [ "$SAFE_COUNT" -gt 0 ]; then
        echo "  💡 ${SAFE_COUNT} sessions marked as IMPLEMENTED can be safely deleted"
        echo "     (Insights have been extracted and applied to system config)"
        read -p "  Delete ${SAFE_COUNT} IMPLEMENTED sessions? [y/N]: " -n 1 -r
        echo

        if [[ $REPLY =~ ^[Yy]$ ]]; then
            log_step "Cleaning up IMPLEMENTED sessions..."

            # Extract temp file path from lifecycle output
            TEMP_FILE=$(echo "$LIFECYCLE_OUTPUT" | grep "^CLEANUP:TEMPFILE:" | cut -d: -f3)

            # Delete sessions using bash + jq (saves ~300ms vs Python interpreter startup)
            if [ -f "$TEMP_FILE" ]; then
                DELETED_COUNT=0
                FREED_BYTES=0

                # Read session paths from JSON array
                while IFS= read -r session_path; do
                    if [ -f "$session_path" ]; then
                        # Get size before deleting
                        SIZE=$(stat -c%s "$session_path" 2>/dev/null || stat -f%z "$session_path" 2>/dev/null || echo "0")
                        SIZE=${SIZE:-0}

                        # Delete session file
                        if rm -f "$session_path" 2>/dev/null; then
                            FREED_BYTES=$((FREED_BYTES + SIZE))
                            DELETED_COUNT=$((DELETED_COUNT + 1))

                            # Delete sidecar metadata file
                            METADATA_PATH="${session_path}.lifecycle.json"
                            rm -f "$METADATA_PATH" 2>/dev/null
                        fi
                    fi
                done < <(jq -r '.[]' "$TEMP_FILE")

                # Calculate freed MB
                FREED_MB=$((FREED_BYTES / 1024 / 1024))

                # Clean up temp file
                rm -f "$TEMP_FILE"

                # Output in same format for parsing
                CLEANUP_RESULT="DELETED:${DELETED_COUNT}
FREED_MB:${FREED_MB}"
            else
                # Fallback if temp file not found
                CLEANUP_RESULT="DELETED:0
FREED_MB:0"
            fi

            DELETED=$(echo "$CLEANUP_RESULT" | grep "^DELETED:" | cut -d: -f2)
            FREED_MB=$(echo "$CLEANUP_RESULT" | grep "^FREED_MB:" | cut -d: -f2)

            log_success "Deleted ${DELETED} IMPLEMENTED sessions (freed ~${FREED_MB}MB)"
            add_action "Cleaned ${FREED_MB}MB of Claude sessions (lifecycle-based)"
        else
            log_warning "Claude session cleanup skipped"
        fi
    elif [ "$VALUABLE_COUNT" -gt 0 ]; then
        echo -e "${YELLOW}  ⚠️  No sessions marked as IMPLEMENTED yet${NC}"
        echo "     All $ANALYZED_COUNT sessions have been analyzed"
        echo "     Next: Review insights → Implement changes → Mark sessions as IMPLEMENTED"
    else
        echo -e "${GREEN}  ✅ No Claude sessions found${NC}"
    fi
fi

# === PHASE 13: Claude Backup Cleanup ===
# Cleans .backups/ directory (old Claude Code backup files)
# Options: delete all, delete >7 days old, or skip
# Exit on failure: No (cleanup is optional)
# Clean up old Claude backup files
if [ -d .backups ]; then
    backup_count=$(fd -t f 'backup-' .backups 2>/dev/null | wc -l)
    if [ "$backup_count" -gt 0 ]; then
        echo ""
        log_step "Found $backup_count Claude backup files in .backups/"
        echo "Options:"
        echo "  1) Delete all backup files (keep only latest version in git)"
        echo "  2) Delete backups older than 7 days"
        echo "  3) Skip cleanup"
        read -p "Choose option (1-3): " -n 1 -r
        echo

        if [[ $REPLY == "1" ]]; then
            # Delete all backup files
            FREED_SPACE=$(fd -t f 'backup-' .backups 2>/dev/null -x du -sb | awk '{sum+=$1} END {print int(sum/1024/1024)}')
            fd -t f 'backup-' .backups 2>/dev/null -X rm
            log_success "Deleted $backup_count backups (freed ~${FREED_SPACE}MB)"
            add_action "Cleaned $backup_count backup files"
        elif [[ $REPLY == "2" ]]; then
            # Delete only old backups
            OLD_COUNT=$(fd -t f 'backup-' .backups --changed-before 7d 2>/dev/null | wc -l)
            FREED_SPACE=$(fd -t f 'backup-' .backups --changed-before 7d 2>/dev/null -x du -sb | awk '{sum+=$1} END {print int(sum/1024/1024)}')
            fd -t f 'backup-' .backups --changed-before 7d 2>/dev/null -X rm
            log_success "Deleted $OLD_COUNT old backups (freed ~${FREED_SPACE}MB)"
            add_action "Cleaned $OLD_COUNT old backup files"
        else
            log_warning "Claude backup cleanup skipped"
        fi
    fi
fi

# === PHASE 14: Git Push ===
# Pushes committed changes to remote repository
# Only runs if user accepted changes in Phase 8
# Exit on failure: No (user can manually push later)
echo ""
read -p "Do you want to push the changes? (y/n) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]
then
    log_step "Pushing to remote..."
    # Wrap git push in error handling to prevent script exit
    if git push 2>&1; then
        log_success "Changes pushed to remote"
        add_action "Pushed to git remote"
    else
        log_warning "Git push failed (check your network/authentication)"
        log_warning "You can push manually later with: git push"
        add_action "Push failed (manual push needed)"
    fi
fi

# Print summary
echo ""
echo "╔════════════════════════════════════════════════════════════╗"
echo "║                    Rebuild Summary                         ║"
echo "╚════════════════════════════════════════════════════════════╝"
echo ""

if [ ${#ACTIONS[@]} -gt 0 ]; then
    echo "📋 Actions completed:"
    for action in "${ACTIONS[@]}"; do
        echo "   ✓ $action"
    done
    echo ""
fi

if [ ${#STATS[@]} -gt 0 ]; then
    echo "📊 Statistics:"
    for stat in "${STATS[@]}"; do
        echo "   • $stat"
    done
    echo ""
fi

if [ ${#WARNINGS[@]} -gt 0 ]; then
    echo -e "${YELLOW}⚠️  Warnings (review recommended):${NC}"
    for warning in "${WARNINGS[@]}"; do
        echo "   • $warning"
    done
    echo ""
fi

if [ "$VERBOSE" = false ]; then
    echo "📁 Detailed logs: $LOG_FILE"
    if [ -f "$LOG_FILE.automation" ]; then
        echo "   Automation logs: $LOG_FILE.automation"
    fi
    echo ""
fi

log_success "NixOS system rebuild and cleanup complete!"
echo ""
